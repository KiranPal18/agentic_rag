{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q chromadb sentence-transformers transformers accelerate scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langgraph langchain langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, time\n",
    "from datetime import datetime, UTC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_DIR = \"./chromadb_langgraph\"\n",
    "EMBED_MODEL = \"all-MiniLM-L6-v2\"\n",
    "LLM_MODEL = \"google/flan-t5-small\"\n",
    "ALERT_THRESHOLD = 0.75\n",
    "SIM_STEPS = 60\n",
    "os.makedirs(CHROMA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = SentenceTransformerEmbeddings(model_name=EMBED_MODEL)\n",
    "vector_store = Chroma(collection_name=\"memory\", embedding_function=embeddings, persist_directory=CHROMA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL)\n",
    "llm_model = AutoModelForSeq2SeqLM.from_pretrained(LLM_MODEL)\n",
    "llm_pipe = pipeline(\"text2text-generation\", model=llm_model, tokenizer=llm_tokenizer, device=-1)\n",
    "\n",
    "def call_local_llm(prompt: str, max_length: int = 256):\n",
    "    out = llm_pipe(prompt, max_length=max_length, do_sample=False)\n",
    "    return out[0][\"generated_text\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"transactions\": [],\n",
    "    \"ticks\": [],\n",
    "    \"fraud_alerts\": [],\n",
    "    \"blocked_accounts\": {},\n",
    "    \"invest_ranking\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_model = None\n",
    "fraud_scaler = None\n",
    "fraud_feat = None\n",
    "inv_model = None\n",
    "inv_scaler = None\n",
    "inv_feat = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transactions(n=1):\n",
    "    merchants = [\"grocery\",\"electronics\",\"crypto\",\"travel\",\"utilities\",\"gambling\"]\n",
    "    for i in range(n):\n",
    "        f = random.random() < 0.08\n",
    "        amt = np.random.exponential(80) + (1000 if f else 0)\n",
    "        tx = {\n",
    "            \"id\": f\"tx_{len(state['transactions'])+i}\",\n",
    "            \"acct\": random.randint(1,2000),\n",
    "            \"amount\": float(amt),\n",
    "            \"merchant\": random.choice(merchants),\n",
    "            \"country\": random.choice([\"US\",\"IN\",\"DE\",\"FR\",\"CA\"]),\n",
    "            \"label\": int(f),\n",
    "            \"timestamp\": datetime.now(UTC).isoformat(),\n",
    "            \"features\": np.array([amt/3000.0, random.random(), 1.0 if f else 0.0, random.random(), random.random()])\n",
    "        }\n",
    "        yield tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ticks(n=1):\n",
    "    syms = [\"AAPL\", \"TSLA\", \"BTC-USD\", \"GOOG\"]\n",
    "    prices = {sym: 100 + random.random() * 50 for sym in syms}\n",
    "    for i in range(n):\n",
    "        sym = random.choice(syms)\n",
    "        change = np.random.normal(0, 0.02)\n",
    "        prices[sym] *= (1 + change)\n",
    "        price = prices[sym]\n",
    "        vol = int(np.random.exponential(100))\n",
    "        label = int(change > 0)\n",
    "        yield {\n",
    "            \"id\": f\"tick_{len(state['ticks'])+i}\",\n",
    "            \"symbol\": sym,\n",
    "            \"price\": float(price),\n",
    "            \"volume\": vol,\n",
    "            \"change\": change,\n",
    "            \"label\": label,\n",
    "            \"features\": np.array([price/200.0, vol/500.0, change, random.random(), random.random()])\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_texts(ids, texts):\n",
    "    vector_store.add_texts(texts, ids=ids)\n",
    "\n",
    "def retrieve_texts(query: str, k: int = 5):\n",
    "    docs = vector_store.similarity_search(query, k=k)\n",
    "    return [d.page_content for d in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fraud(batch):\n",
    "    global fraud_model, fraud_scaler, fraud_feat\n",
    "    if not batch:\n",
    "        return []\n",
    "    X = np.vstack([t[\"features\"] for t in batch])\n",
    "    y = np.array([t[\"label\"] for t in batch])\n",
    "    if (fraud_model is None) or (fraud_feat != X.shape[1]):\n",
    "        fraud_model = SGDClassifier(loss=\"log_loss\", max_iter=5, tol=None, learning_rate=\"adaptive\", eta0=0.01)\n",
    "        fraud_scaler = StandardScaler()\n",
    "        fraud_scaler.fit(X)\n",
    "        fraud_model.partial_fit(fraud_scaler.transform(X), y, classes=[0, 1])\n",
    "        fraud_feat = X.shape[1]\n",
    "        print(f\"[INFO] Fraud model initialized ({fraud_feat} features).\")\n",
    "    else:\n",
    "        fraud_model.partial_fit(fraud_scaler.transform(X), y)\n",
    "    probs = fraud_model.predict_proba(fraud_scaler.transform(X))[:, 1]\n",
    "    alerts = []\n",
    "    for t, p in zip(batch, probs):\n",
    "        if p > ALERT_THRESHOLD:\n",
    "            alerts.append({\n",
    "                \"tx_id\": t[\"id\"],\n",
    "                \"acct\": t[\"acct\"],\n",
    "                \"prob\": round(float(p), 3),\n",
    "                \"amount\": t[\"amount\"],\n",
    "                \"merchant\": t[\"merchant\"],\n",
    "                \"country\": t[\"country\"],\n",
    "                \"timestamp\": t[\"timestamp\"]\n",
    "            })\n",
    "    if alerts:\n",
    "        print(f\"###### {len(alerts)} fraud alerts detected\")\n",
    "        for a in alerts:\n",
    "            print(f\"  TX={a['tx_id']} ACC={a['acct']} PROB={a['prob']} AMT={a['amount']}\")\n",
    "        state[\"fraud_alerts\"].extend(alerts)\n",
    "    return alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_invest(batch):\n",
    "    global inv_model, inv_scaler, inv_feat\n",
    "    if not batch: return []\n",
    "    X = np.vstack([t[\"features\"] for t in batch])\n",
    "    y = np.array([t[\"label\"] for t in batch])\n",
    "    if (inv_model is None) or (inv_feat != X.shape[1]):\n",
    "        inv_model = SGDClassifier(loss=\"log_loss\", max_iter=5, tol=None)\n",
    "        inv_scaler = StandardScaler()\n",
    "        inv_scaler.fit(X)\n",
    "        inv_model.partial_fit(inv_scaler.transform(X), y, classes=[0,1])\n",
    "        inv_feat = X.shape[1]\n",
    "    else:\n",
    "        inv_model.partial_fit(inv_scaler.transform(X), y)\n",
    "    probs = inv_model.predict_proba(inv_scaler.transform(X))[:,1]\n",
    "    df = pd.DataFrame({\"symbol\":[t[\"symbol\"] for t in batch],\"prob\":probs})\n",
    "    ranking = df.groupby(\"symbol\")[\"prob\"].mean().sort_values(ascending=False)\n",
    "    state[\"invest_ranking\"] = list(ranking.items())\n",
    "    return state[\"invest_ranking\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_blocked(alerts):\n",
    "    for a in alerts:\n",
    "        acc = a[\"acct\"]\n",
    "        info = state[\"blocked_accounts\"].get(acc, {\"count\":0,\"blocked\":False})\n",
    "        info[\"count\"] += 1\n",
    "        if info[\"count\"] >= 3:\n",
    "            info[\"blocked\"] = True\n",
    "        state[\"blocked_accounts\"][acc] = info\n",
    "\n",
    "def get_blocked():\n",
    "    return [k for k,v in state[\"blocked_accounts\"].items() if v.get(\"blocked\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fraud_summary(n=5):\n",
    "    df = pd.DataFrame(state[\"fraud_alerts\"])\n",
    "    if df.empty: return []\n",
    "    return df.sort_values(\"prob\", ascending=False).head(n).to_dict(\"records\")\n",
    "\n",
    "def get_investment_picks(n=3):\n",
    "    return state[\"invest_ranking\"][:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_answer(query: str, retrieved, tool_outputs):\n",
    "    prompt = f\"\"\"\n",
    "    You are **FinGuard**, an AI financial intelligence assistant.\n",
    "    Your task is to provide **clear, factual, and risk-aware** insights\n",
    "    based on both structured model outputs and retrieved historical context.\n",
    "    User query: {query}\n",
    "    Structured data:{tool_outputs}\n",
    "    Retrieved context:{retrieved[:3]}\n",
    "    Explain clearly and concisely.\"\"\"\n",
    "    return call_local_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_intent(s):\n",
    "    q = s[\"query\"].lower()\n",
    "    if \"fraud\" in q: s[\"intent\"] = \"fraud\"\n",
    "    elif \"invest\" in q: s[\"intent\"] = \"invest\"\n",
    "    elif \"block\" in q: s[\"intent\"] = \"block\"\n",
    "    else: s[\"intent\"] = \"general\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_node(s):\n",
    "    s[\"retrieved\"] = retrieve_texts(s[\"query\"], k=5)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_node(s):\n",
    "    intent = s.get(\"intent\")\n",
    "    tools = {}\n",
    "    if intent == \"fraud\": tools[\"fraud_summary\"] = get_fraud_summary()\n",
    "    if intent == \"invest\": tools[\"invest_picks\"] = get_investment_picks()\n",
    "    if intent == \"block\":\n",
    "        tools[\"blocked_accounts\"] = [{\"account\": acc, \"details\": state[\"blocked_accounts\"][acc]} for acc in get_blocked()]\n",
    "    s[\"tool_outputs\"] = tools\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_reason_node(s):\n",
    "    s[\"answer\"] = synthesize_answer(s[\"query\"], s.get(\"retrieved\", []), s.get(\"tool_outputs\", {}))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Any\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    intent: str\n",
    "    retrieved: list\n",
    "    tool_outputs: dict\n",
    "    answer: str\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"ClassifyIntent\", classify_intent)\n",
    "graph.add_node(\"RetrieveRAG\", retrieve_node)\n",
    "graph.add_node(\"RunTools\", tool_node)\n",
    "graph.add_node(\"LLMReason\", llm_reason_node)\n",
    "graph.add_edge(\"ClassifyIntent\", \"RetrieveRAG\")\n",
    "graph.add_edge(\"RetrieveRAG\", \"RunTools\")\n",
    "graph.add_edge(\"RunTools\", \"LLMReason\")\n",
    "graph.add_edge(\"LLMReason\", END)\n",
    "graph.set_entry_point(\"ClassifyIntent\")\n",
    "agent_graph = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(steps=SIM_STEPS):\n",
    "    for step in range(steps):\n",
    "        tx_batch = list(generate_transactions(random.randint(10,30)))\n",
    "        tick_batch = list(generate_ticks(random.randint(5,15)))\n",
    "        state[\"transactions\"].extend(tx_batch)\n",
    "        state[\"ticks\"].extend(tick_batch)\n",
    "        index_texts([t[\"id\"] for t in tx_batch], [f\"Transaction {t['id']} amount={t['amount']} merchant={t['merchant']} label={t['label']}\" for t in tx_batch])\n",
    "        index_texts([t[\"id\"] for t in tick_batch], [f\"Tick {t['id']} symbol={t['symbol']} price={t['price']}\" for t in tick_batch])\n",
    "        alerts = train_fraud(tx_batch)\n",
    "        update_blocked(alerts)\n",
    "        train_invest(tick_batch)\n",
    "        if step % 10 == 0:\n",
    "            print(f\"[STEP {step}] TX={len(state['transactions'])} FRAUD={len(state['fraud_alerts'])} BLOCKED={len(get_blocked())}\")\n",
    "        time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulation(10)\n",
    "\n",
    "queries = [\n",
    "    \"Show me recent fraud alerts and risky accounts.\",\n",
    "    \"Which accounts are currently blocked?\",\n",
    "    \"Give me the top investment picks right now.\"\n",
    "]\n",
    "for q in queries:\n",
    "    print(f\"\\n> Query: {q}\")\n",
    "    result = agent_graph.invoke({\"query\": q})\n",
    "    print(\"🧠 Agentic Answer:\\n\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
